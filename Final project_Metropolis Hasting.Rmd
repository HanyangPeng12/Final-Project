---
title: "Stat 378 Final Project Matropolis-Hasting Alagorithm"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#Report on Matropolis-Hasting Alagorithm

In order to understand a certain distribution $p(x)$, the idea of MCMC is to simulate a Markov chain whose equilibrium distribution is $p(x)$, and metropolis-hasting algorithm provides a way to generate the Markov chain. Giving a start value, and with the help of proposal function, M-H produce a new proposed value based only on its previous value in the Markov chain and decide whether to accept the new value by the acceptance rate. If accepted, the chain moves to the new value, and if not, the chain stays with the old value. By repeating these steps, M-H could generate a chain to simulate the distribution.

Below is the metropolis-hasting algorithm sample from a beta distribution $\phi$ with parameters (6,4). We would explain the algorithm and how we implemented it later.
```{r}
mh.beta <- function(iterations, start,shape1, shape2,c) {
  phi.old <- start
  #set the intitial value to be the start value
  draws <- c()
  #save the values of chain in a vector
  phi.update <- function(phi.old, shape1, shape2) {
    phi.new <- rbeta(1, c*phi.old, c*(1-phi.old))
    #generate the new value
    accept.prob <- dbeta(phi.new, shape1 = shape1, shape2=shape2)/dbeta(phi.old,shape1 = shape1, shape2 = shape2)*
      (dbeta(phi.old,c*phi.new,c*(1-phi.new))/dbeta(phi.new,c*phi.old,c*(1-phi.old)))
    #caculate the acceptance probability of the new value with a correction factor
    if (runif(1) <= accept.prob) 
    {phi.update=phi.new} 
    #if the acceptance probability is larger then accept the new value 
    else 
        {phi.update=phi.old}
  }
  # if the acceptance probability is lower then stay with the old value 
  for (i in 1:iterations) {
    draws[i] <- phi.old <- phi.update(phi.old, shape1 = shape1,
                                          shape2 = shape2)
  }
  #give the new value to the chain
  return(draws[1:iterations])
}
```

The algorithm is generally a function to describe the process of M-H. The input of the function would be the times of iterations, which refers to the length of chain we want, the start value, two shape parameters of the beta distribution, and the parameter "c" in the proposal function. 

In the function, we use "phi.old" to save the old value of the chain, use "phi.new" to save the new value generated from the old value, the function we use to generate the new value is called "phi.update", and we save the result of the chain in the vector "draw".

When iterating for the first time, we set the "phi.old" to be the start value. Then, we generate a new value based on the start value by proposal function. As mentioned in the problem, the proposal function is of the form $\phi_{old}| \phi_{new} \sim  Beta(c*\phi_{old},c*(1-\phi_{old}))$, which means the new value is generated by producing a random number from the given beta distribution. We notice that, in the beta distribution of the proposal function, the shape parameters are determined by a variable $c$ and the old value of $\phi$, that's just how old value would generate a new value in M-H algorithm.

After generating the new value, we need to decide whether to accept the new value. The criterion for accepting or rejecting the new value is as follow: (we denote $x$ as old value, and $x^*$ as the new value)  
1.If $p(x^*) \geq p(x)$, that means $p(x)$ has high density near $x^*$, and will be accepted as the new value in the chain.  
2. If $p(x^*) < p(x)$, that indicates that $p(x)$ has low density near $x^*$. In that case, the new value may still be accepted, but only randomly, and with a probability $\frac{p(x^*)}{p(x)}$.  
However, we must notice that beta distribution is not symmetric, which means the proposal function needs a correction factor to suit the reversibility condition of Markov chain. The correction factor is defined as $C=\frac{q(x^{(t-1)} | x^*) }{q(x^* | x^{(t-1)})}$, where $q$ refers to the density function of each conditional distribution. Therefore, we could calculate the acceptance rate $\alpha$ by $\alpha = \text{min} \left (1,\frac{p(x^*)}{p(x)} \times C\right)$.

To implement such process, we draw a random number $u$ from distribution $Unif(0,1)$. If $u \leq \alpha$, we accept the new value; if $u>\alpha$ the new value would be rejected and the chain would stay with the old value.

Finally, we save the value into the chain vector, and update the value of $\phi$. In further iterations, we repeat this process until we get a chain with desired length.

#Problem 2
The trace plot, autocorrelation plot, and histogram of the draws are as below. 
```{r}
draws<-mh.beta(10000, start = runif(1),shape1 = 6, shape2 = 4,c=1)
par(mfrow=c(1,3))  #1 row, 3 columns
 plot(draws)
 acf(draws)
 hist(draws) 
```

The comparison between the histogram of draws and target distribution of Beta(6,4) is as below.
```{r}
x=seq(0,1,0.001)
hist(draws,freq=F,main="Comparing draws with target distribution")
lines(x,dbeta(x,6,4),col="red")
```

```{r}
ks.test(draws,"pbeta",6,4)
```

According to the comparison of histogram and the result of K-S test, the distribution of draws follows the target distribution Beta(6,4) quite well. The histogram shows that the sampler generally have the same distribution as beta distribution with shape parameters (6,4). The result of K-S test shows that we are quite confident that the sampler and the target distribution shares the same distribution, since both the distance and the p-value of K-S test are quite low.

Therefore, we can conclude that the sampler could simulate the target distribution quite accurately.

#Problem 3
```{r}
draws<-mh.beta(10000, start = runif(1),shape1 = 6, shape2 = 4,c=0.1)
par(mfrow=c(1,3))  #1 row, 3 columns
 plot(draws)
 acf(draws)
 hist(draws,freq=F) 
lines(x,dbeta(x,6,4),col="red")
ks.test(draws,"pbeta",6,4) 
```

```{r}
draws<-mh.beta(10000, start = runif(1),shape1 = 6, shape2 = 4,c=2.5)
par(mfrow=c(1,3))  #1 row, 3 columns
 plot(draws)
 acf(draws)
 hist(draws,freq=F) 
 lines(x,dbeta(x,6,4),col="red")
 ks.test(draws,"pbeta",6,4)
```

```{r}
draws<-mh.beta(10000, start = runif(1),shape1 = 6, shape2 = 4,c=10)
par(mfrow=c(1,3))  #1 row, 3 columns
 plot(draws)
 acf(draws)
 hist(draws,freq=F) 
 lines(x,dbeta(x,6,4),col="red")
 ks.test(draws,"pbeta",6,4)
```








