---
title: "final project - k-means"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
data(wine, package="rattle")
library('fpc')
set.seed(11)
data.train = wine[,-1]
fit.km = kmeans(data.train,3)
plotcluster(data.train, fit.km$cluster)
fit.km
```

```{r}
fit_type=as.matrix(fit.km$centers)
wine_type_data=rbind(apply(wine[which(wine[,1]==1),-1],2,mean),apply(wine[which(wine[,1]==2),-1],2,mean),apply(wine[which(wine[,1]==3),-1],2,mean))
wine_type=as.matrix(wine_type_data)
test1=matrix(0,3,3)
for(i in 1:3){
  for(j in 1:3){
    test1[i,j]=sum((fit_type[i,]-wine_type[j,])^2)
  }
}
test1
#fit1=fit.km$centers[1,]
#fit2=fit.km$centers[2,]
#fit3=fit.km$centers[3,]
#wine1=apply(wine[which(wine[,1]==1),-1],2,mean)
#wine2=apply(wine[which(wine[,1]==2),-1],2,mean)
#wine3=apply(wine[which(wine[,1]==3),-1],2,mean)
```

According to the outcome, we can see the types 

### Clusters analysis 1
(1)According to the plot, one can observe that the majority of the samples are separated into three different clusters. However, some samples which are separated into different clusters are very close to each other, and some of them are even enclosed by samples in other clusters. As a result, the outcome of clusters make sense to some degree but maybe not quite well.
(2)It can be seen that between_SS / total_SS =  85.1 %, which means that the distance between clusters are relatively large, and the clusters are well-separated to some extent but not quite well.




